## 简介
在此模块中，我们将探讨用于处理自然语言文本的不同神经网络体系结构。 近年来，自然语言处理 (NLP) 经历了快速增长，主要是由于语言模型在大型文本语料库上以无监督的方式进行训练的同时，能够更快地准确“理解”人类语言。 例如，使用 GPT-3 或预先训练的文本模型（如 BERT）生成句子简化了许多 NLP 任务，并显著提高了性能。

我们将重点介绍在 PyTorch 中将 NLP 表示为张量的基础方面，以及经典的 NLP 体系结构，例如使用词袋 (BoW)、词嵌入、递归神经网络和生成网络。

### 自然语言任务
我们传统上尝试使用神经网络解决几个 NLP 任务：

- 文本分类，当我们需要将文本片段分类为几个预定义的类之一时使用。 示例包括电子邮件垃圾邮件检测、新闻分类、将支持请求分配给其中一个类别等。
- 意向分类，它是文本分类的一种特定情况，当我们想要将对话式 AI 系统中的输入话语映射到表示短语或用户意向的实际含义的意向之一时使用。
- 情绪分析，这是一个回归任务，通过执行此任务，我们可以了解给定文本的否定程度。 我们可以对数据集中的文件进行标记，用 -1（否定）到 + 1（肯定）来表示否定程度，并训练一个模型，使其能够输出许多表示“肯定”的文本。
- 命名实体识别 (NER)，此任务从文本中提取某些实体，例如日期、地址、人员姓名等。与意向分类一起，NER 通常用于对话系统，以从用户的话语中提取参数。
- 与此类似的任务是关键字提取，可用于查找文本中最有意义的单词，然后可以用作标记。
- 文本摘要，提取最有意义的文本片段，为用户提供包含大部分含义的压缩版本。
- 问题/答案，是从一段文本中提取答案的任务。 此模型获取文本片段和问题作为输入，并需要在包含答案的文本中查找确切的位置。 例如，如果文本是“John 是一名喜欢使用 Microsoft Learn 的 22 岁学生”，那么应为我们提供问题“John 多少岁了”并包含答案“22 岁”。
对于本模块的范围，我们将主要介绍文本分类任务。 我们将使用新闻头条中的文本来分类它们属于 4 个类别中的哪一个：世界、体育、商业和科技。 我们还将介绍可自行生成类人的文本序列的生成模型。

### 学习目标
通过学习本模块，你将能够：

- 了解如何处理自然语言处理任务的文本
- 了解如何使用递归神经网络 (RNN) 和生成网络
- 了解如何生成文本分类模型
### 先决条件
- Python 基础知识
- 对如何使用 Jupyter Notebook 有基本的了解
- 对机器学习有基本的了解