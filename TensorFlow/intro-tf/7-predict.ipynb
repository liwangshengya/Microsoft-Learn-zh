{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Matplotlib is building the font cache; this may take a moment.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by including the code that gets the data and model:\r\n",
        "\r\n",
        "让我们从包含获取数据和模型的代码开始："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -Nq https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-tf/tintro.py\n",
        "from tintro import *"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to make a prediction, we need to pass some data to the model, and do a single forward pass through the network to get the prediction. If the code below is unclear to you, make sure you go back to module 1, where we explain it in detail. Remember that, unlike during testing, we don't need to call the loss function because we're no longer interested in evaluating how well the model is doing. Instead, we call `softmax` to convert the values of the output vector into values between 0 and 1, and then get the `argmax` of that vector to get the predicted label index.\n",
        "\n",
        "Similarly to the training and testing sections, once we're done with debugging, we can add a `@tf.function` decorator to get the performance benefits of graph execution.\n",
        "\n",
        "为了进行预测，我们需要将一些数据传递给模型，并通过网络进行一次前向传递以获得预测。 如果您不清楚下面的代码，请务必返回模块 1，我们会在其中对其进行详细解释。 请记住，与测试期间不同，我们不需要调用损失函数，因为我们不再对评估模型的表现感兴趣。 相反，我们调用 `softmax` 将输出向量的值转换为 0 到 1 之间的值，然后获取该向量的 `argmax` 以获得预测的标签索引。\n",
        "\n",
        "与训练和测试部分类似，完成调试后，我们可以添加一个`@tf.function`装饰器来获得图形执行的性能优势。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def predict(model: tf.keras.Model, X: np.ndarray) -> tf.Tensor:\n",
        "  y_prime = model(X, training=False)\n",
        "  probabilities = tf.nn.softmax(y_prime, axis=1)\n",
        "  predicted_indices = tf.math.argmax(input=probabilities, axis=1)\n",
        "  return predicted_indices"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now make a prediction. First we'll get the image we'll use for prediction.\r\n",
        "\r\n",
        "我们现在可以做出预测。 首先，我们将获得用于预测的图像。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_weights('outputs/weights')\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-keras/predict-image.png'\n",
        "\n",
        "with Image.open(requests.get(url, stream=True).raw) as image:\n",
        "  X = np.asarray(image, dtype=np.float32).reshape((-1, 28, 28)) / 255.0\n",
        "\n",
        "plt.figure()\n",
        "plt.axis('off')\n",
        "plt.imshow(X.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're now ready to make the prediction by passing the image we read into the `predict` function.\r\n",
        "\r\n",
        "我们现在准备好通过将我们读取的图像传递给`predict`函数来进行预测。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_index = predict(model, X).numpy()[0]\n",
        "predicted_name = labels_map[predicted_index]\n",
        "\n",
        "print(f'Predicted class: {predicted_name}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Predicted class: Ankle Boot\n"
        }
      ],
      "execution_count": 5,
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a7d8d32a02de2fe32a77a4e581138922e011c09664b6c2991156e76c4176efab"
    },
    "kernelspec": {
      "name": "conda-env-azureml_py38-py",
      "language": "python",
      "display_name": "azureml_py38"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "azureml_py38_PT_and_TF"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}