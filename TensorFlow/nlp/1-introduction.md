在此模块中，我们将探讨用于处理自然语言文本的不同神经网络体系结构。 近年来，自然语言处理 (NLP) 领域经历了快速发展，这既是因为语言模型体系结构得到了改进，也是因为它们接受了越来越大的文本语料库的训练。 结果，它们“理解”文本的能力得到了极大的改进，BERT 等大型预训练模型得到了广泛应用。

我们将重点介绍在 TensorFlow 中将 NLP 表示为张量的基础方面，以及经典的 NLP 体系结构，例如使用词包、嵌入和递归神经网络。

## 自然语言任务

使用神经网络可解决的几个 NLP 任务：

* **文本分类** ，当我们需要将文本片段分类为几个预定义的类之一时使用。 示例包括电子邮件垃圾邮件检测、新闻分类、将支持请求分配给其中一个类别等。
* **意向分类** ，它是文本分类的一种特定情况，当我们想要将对话式 AI 系统中的输入话语映射到表示短语或用户意向的实际含义的意向之一时使用。
* **情绪分析** ，这是一个回归任务，通过执行此任务，我们可以了解给定文本的否定程度。 我们可以对数据集中的文件进行标记，用 -1（否定）到 + 1（肯定）来表示否定程度，并训练一个模型，使其能够输出表示肯定输入文本的数字。
* **命名实体识别** (NER)，此任务从文本中提取实体，例如日期、地址、人员姓名等。与意向分类一起，NER 通常用于对话系统，以从用户的话语中提取参数。
* 与此类似的任务是关键字提取，可用于查找文本中最有意义的单词，然后可以用作标记。
* **文本摘要** ，提取最有意义的文本片段，为用户提供原始文本的压缩版本。
* **问题/答案** ，此任务从一段文本中提取答案。 此模型使用文本片段和问题作为输入，并需要在包含答案的文本中查找确切的位置。 例如，如果文本是“John 是一名喜欢使用 Microsoft Learn 的 22 岁学生”，那么应为我们提供问题“John 多少岁了”并包含答案“22 岁”。

在此模块中，我们将主要介绍文本分类任务。 此外，还将介绍将来处理更困难的任务所需的所有重要概念。

## 学习目标

* 了解 NLP 任务是如何处理文本的
* 了解递归神经网络 (RNN) 和生成神经网络 (GNN)
* 了解注意机制
* 了解如何生成文本分类模型

## 先决条件

* Python 相关知识
* 对机器学习有基本的了解
