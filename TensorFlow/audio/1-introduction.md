你有想过语音助理的实际工作方式是怎样的吗？ 它们如何理解我们所说的话？ 当你想到语音助理时，第一步是语音转文本，然后是自然语言处理 (NLP) 步骤，即话语嵌入（将话语转化为数字），然后是对言语（人们说的话）和意图（他们希望语音助理做的事）的分类。 如果遵循此学习路径，你就会了解 NLP 部件是如何工作的。 现在，我们将了解如何获取音频中的文本。 音频分类适用于许多服务，而不仅仅是语音助理。 例如，在音乐方面，你可以对流派进行分类或通过某人语音中的音调来检测他是否身体不适，甚至还可以应用到更多我们从未想到的方面。

此学习模块将介绍如何使用 TensorFlow 进行音频分类。 可通过多种方法生成音频分类模型。 可以使用波形文件的波形标记部分，甚至可以对光谱图图像使用计算机视觉。 在本教程中，我们将详细讲解如何理解音频数据（从模拟到数字表示形式），然后对声谱图使用计算机视觉生成模型。 没错，你可以将音频转换为图像表示形式，然后使用计算机视觉对所说的话进行分类！ 我们将构建一个简单的模型，该模型可以理解 `yes` 和 `no`。 我们将使用的数据集是内置于 TensorFlow 数据集的开放数据集 Speech Commands。 此数据集一共有 36 个/种不同的字词/声音，用于分类。 每个语句都存储为时长为一秒（或更短）的 WAVE 格式化文件。 我们将仅使用 `yes` 和 `no` 进行二元分类。

## 学习目标

* 了解音频数据的一些重要功能。
* 介绍如何生成音频机器学习模型。
* 了解如何从波形文件生成二元分类模型。

## 先决条件

* Python 相关知识
* 对机器学习有基本的了解
