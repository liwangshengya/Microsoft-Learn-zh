{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import tensorflow as tf"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we start re-implementing portions of our Keras code, we need to understand TensorFlow's basic concepts. In this notebook, we'll cover tensors and variables.\n",
        "\n",
        "In TensorFlow, a [`Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor) is the data structure used to store the inputs and outputs of a deep learning model. A [`Variable`](https://www.tensorflow.org/api_docs/python/tf/Variable) is a special type of tensor that is used to store any model parameters that need to be learned during training. The difference here is that tensors are immutable and variables are mutable. They're both super important concepts to understand if you're going to be working with TensorFlow.\n",
        "\n",
        "Mathematically speaking, a tensor is just a generalization of vectors and matrices. A vector is a one-dimensional array of values, a matrix is a two-dimensional array of values, and a tensor is an array of values with any number of dimensions. A TensorFlow `Tensor`, much like NumPy's `ndarray`, gives us a way to represent multidimensional data, but with added tricks, such as the ability to perform operations on a GPU and the ability to calculate derivatives.\n",
        "\n",
        "Suppose we want to represent this 3 &times; 2 matrix in TensorFlow:\n",
        "\n",
        "$$\n",
        "X = \n",
        "\\begin{bmatrix}\n",
        "  1 & 2 \\\\\n",
        "  3 & 4 \\\\\n",
        "  5 & 6\n",
        "\\end{bmatrix} \n",
        "$$\n",
        "\n",
        "Here's the code to create the corresponding tensor:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.constant([[1, 2], [3, 4], [5, 6]])"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can inspect the tensor's `shape` attribute to see how many dimensions it has and the size in each dimension. The `device` attribute tells us whether the tensor is stored on the CPU or GPU, and the `dtype` attribute indicates what kind of values it holds. We use the `type` function to check the type of the tensor itself."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(X.device)\n",
        "print(X.dtype)\n",
        "print(type(X))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(3, 2)\n/job:localhost/replica:0/task:0/device:CPU:0\n<dtype: 'int32'>\n<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that if your machine is configured properly for TensorFlow to take advantage of a GPU, then TensorFlow will automatically decide whether to store tensors and perform tensor math on the GPU or CPU in an optimal way, without any additional work on your part.\n",
        "\n",
        "If you've used NumPy ndarrays before, you might be happy to know that TensorFlow tensors can be indexed in a familiar way. We can slice a tensor to view a smaller portion of it:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[0:2, 0:1]\n",
        "X"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\narray([[1],\n       [3]], dtype=int32)>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also convert tensors to NumPy arrays by simply using the `numpy` method:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "array = X.numpy()           \n",
        "array"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "array([[1],\n       [3]], dtype=int32)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables can easily be initialized from tensors: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "V = tf.Variable(X)\n",
        "V"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "<tf.Variable 'Variable:0' shape=(2, 1) dtype=int32, numpy=\narray([[1],\n       [3]], dtype=int32)>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we mentioned earlier, unlike a `Tensor`, a `Variable` is mutable. We can update the value of our variable using the `assign`, `assign_add`, and `assign_sub` methods:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "Y = tf.constant([[5], [6]])\n",
        "V.assign(Y)\n",
        "V"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "<tf.Variable 'Variable:0' shape=(2, 1) dtype=int32, numpy=\narray([[5],\n       [6]], dtype=int32)>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "V.assign_add([[1], [1]])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "<tf.Variable 'UnreadVariable' shape=(2, 1) dtype=int32, numpy=\narray([[6],\n       [7]], dtype=int32)>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "V.assign_sub([[2], [2]])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "<tf.Variable 'UnreadVariable' shape=(2, 1) dtype=int32, numpy=\narray([[4],\n       [5]], dtype=int32)>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a7d8d32a02de2fe32a77a4e581138922e011c09664b6c2991156e76c4176efab"
    },
    "kernelspec": {
      "display_name": "azureml_py38",
      "language": "python",
      "name": "conda-env-azureml_py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}